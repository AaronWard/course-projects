{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Capstone Project\n",
    "- Clean text (Tokenize, lower, remove stopwords, lemmentize, stem etc)\n",
    "- Train 24 Topic Models for each topic label\n",
    "- Do inference on larger sample to get probabilities as features\n",
    "- CountVectorizer on words for features\n",
    "- Use Average word length as feature\n",
    "- length of document\n",
    "- Scale Features\n",
    "- Train Neural Network\n",
    "\n",
    "\"Your goal is to predict the topic(s) of publications from the World Bank, where there are 24 possible topics. <br>\n",
    "You will be given the first six pages of text from each dociument. <br>Each document has at least one topic and can have multiple topics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/award40/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/award40/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import gensim\n",
    "import pickle\n",
    "# import pyLDAvis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from baggingPU import BaggingClassifierPU\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing and Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "TRAINING_DATA = '../wb-publications-data/train_values.csv'\n",
    "TRAINING_LABEL = '../wb-publications-data/train_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = pd.read_csv(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(TRAINING_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_values, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample data to text out preprocessing\n",
    "df = df_all[:10000].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "     return [lemmatizer.lemmatize(word) for word in text]\n",
    "        \n",
    "def preprocess_text(df):\n",
    "    exclude = set(string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update((\"develop\", \"develops\", \"developing\", \"busi\", \"business\", \"businesses\", \"program\", \"programs\"))\n",
    "    \n",
    "    #Preprocess text column\n",
    "    df['processed_text'] = df.doc_text.str.replace(r'\\d+', '')                                  #Remove number\n",
    "    df['processed_text'] = df.processed_text.str.lower()                                        #lower\n",
    "    df['processed_text'] = df.processed_text.str.replace('http\\S+|www.\\S+', '', case=False)     #Remove website links\n",
    "    df[\"processed_text\"] = df.processed_text.str.replace('[{}]'.format(string.punctuation), '') #Remove all punctations\n",
    "\n",
    "    df['processed_text'] = df.apply(lambda row: word_tokenize(row[\"processed_text\"]), axis=1)\n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.rstrip() for word in x])                       #Remove white spaces\n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.replace('\\n', ' ') for word in x])             #Remove literal blackslashes  \n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.replace(r\"\\s\\s+\",' ') for word in x])          #Remove White spaces \n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.strip() for word in x if len(word) > 4])       #Remove spaces out words and acronyms\n",
    "\n",
    "    #Remove stop words \n",
    "    df[\"topic_processed_text\"] = df.processed_text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lambda x: [word for word in x if word not in exclude])\n",
    "    \n",
    "    #Lemmantize Words\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lemmatize_text)\n",
    "    \n",
    "    #Stemming\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>topic_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...</td>\n",
       "      <td>[findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...</td>\n",
       "      <td>[find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>[decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...</td>\n",
       "      <td>[decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...</td>\n",
       "      <td>[taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...</td>\n",
       "      <td>[take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WPS5836\\n\\n\\nPolicy Research Working Paper     ...</td>\n",
       "      <td>[policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...</td>\n",
       "      <td>[polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1                                   WPS39...</td>\n",
       "      <td>[relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...</td>\n",
       "      <td>[rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              doc_text  \\\n",
       "0  84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...   \n",
       "1                                                                                                  ...   \n",
       "2                             78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...   \n",
       "3                                                   WPS5836\\n\\n\\nPolicy Research Working Paper     ...   \n",
       "4                                                         1                                   WPS39...   \n",
       "\n",
       "                                                                                        processed_text  \\\n",
       "0  [findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...   \n",
       "1  [decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...   \n",
       "2  [taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...   \n",
       "3  [policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...   \n",
       "4  [relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...   \n",
       "\n",
       "                                                                                  topic_processed_text  \n",
       "0  [find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...  \n",
       "1  [decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...  \n",
       "2  [take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...  \n",
       "3  [polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...  \n",
       "4  [rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['doc_text', 'processed_text', 'topic_processed_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create names for each model based on label names\n",
    "topics = []\n",
    "for col in df_labels.columns:\n",
    "    if col != 'row_id':\n",
    "        topics.append(str(col))\n",
    "topics = set(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "corpai = {}\n",
    "dicts = {}\n",
    "visualizations = {}\n",
    "\n",
    "def create_bag_of_words(df):\n",
    "    dictionary = corpora.Dictionary(df.topic_processed_text.values)\n",
    "    dictionary.filter_extremes(no_below=5, keep_n=1000)\n",
    "    corpus = [dictionary.doc2bow(text) for text in df.topic_processed_text.values]\n",
    "    \n",
    "    return dictionary, corpus\n",
    "\n",
    "\n",
    "def create_models(corp, dic):\n",
    "    return gensim.models.ldamodel.LdaModel(corp, num_topics = 3, id2word = dic, passes=20)\n",
    "\n",
    "\n",
    "def top_terms_per_topic(lda_model):\n",
    "    top_words_per_topic = []\n",
    "    for t in range(lda_model.num_topics):\n",
    "        top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
    "\n",
    "    return pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P'])\n",
    "\n",
    "\n",
    "'''\n",
    "Iterate over topic columns, create temp df frame and train LDA models \n",
    "Store them in dictionaries. \n",
    "'''\n",
    "def train_topic_models(df):\n",
    "    print('Begin Training Topic Models ')\n",
    "    for category in topics:\n",
    "        print('...{}'.format('Training topic model for '+ category))\n",
    "\n",
    "        #Drop all useless labels\n",
    "        tmp_df = df[df[category] == 1]\n",
    "        tmp_df = tmp_df[[category, 'topic_processed_text']]\n",
    "                \n",
    "        print('...{}'.format(tmp_df[category].value_counts()))\n",
    "\n",
    "        # Create Dictionary\n",
    "        dictionary, corpus = create_bag_of_words(df)\n",
    "        lda_model = create_models(corpus, dictionary)\n",
    "        \n",
    "        #Add models to dictionary\n",
    "        models[category] = lda_model\n",
    "        corpai[category] = corpus\n",
    "        dicts[category] = dictionary\n",
    "        \n",
    "\n",
    "        #Save Models and top terms\n",
    "        top_topics = top_terms_per_topic(lda_model) \n",
    "        top_topics.to_csv(\"./topic_models/top_terms_{}.csv\".format(category))\n",
    "        lda_model.save('./topic_binaries/lda_{}.model'.format(category))\n",
    "        print('\\n')\n",
    "\n",
    "    print('Topic Reports Saved...')\n",
    "    print('Topic Binary Saved...')\n",
    "    return models, corpai, dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training Topic Models \n",
      "...Training topic model for infrastructure_economics_and_finance\n",
      "...1    173\n",
      "Name: infrastructure_economics_and_finance, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for public_sector_development\n",
      "...1    1401\n",
      "Name: public_sector_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for information_and_communication_technologies\n",
      "...1    412\n",
      "Name: information_and_communication_technologies, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for poverty_reduction\n",
      "...1    1359\n",
      "Name: poverty_reduction, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for social_development\n",
      "...1    842\n",
      "Name: social_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for conflict_and_development\n",
      "...1    405\n",
      "Name: conflict_and_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for governance\n",
      "...1    881\n",
      "Name: governance, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for energy_and_environment\n",
      "...1    1707\n",
      "Name: energy_and_environment, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for science_and_technology_development\n",
      "...1    467\n",
      "Name: science_and_technology_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for health_and_nutrition_and_population\n",
      "...1    1798\n",
      "Name: health_and_nutrition_and_population, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for agriculture\n",
      "...1    609\n",
      "Name: agriculture, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for urban_development\n",
      "...1    700\n",
      "Name: urban_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for international_economics_and_trade\n",
      "...1    1272\n",
      "Name: international_economics_and_trade, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for social_protections_and_labor\n",
      "...1    1219\n",
      "Name: social_protections_and_labor, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for rural_development\n",
      "...1    989\n",
      "Name: rural_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for gender\n",
      "...1    571\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for water\n",
      "...1    869\n",
      "Name: water, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for finance_and_development\n",
      "...1    4805\n",
      "Name: finance_and_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for culture_and_development\n",
      "...1    163\n",
      "Name: culture_and_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for transport\n",
      "...1    807\n",
      "Name: transport, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for law_and_development\n",
      "...1    1271\n",
      "Name: law_and_development, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for macroeconomics_and_growth\n",
      "...1    4308\n",
      "Name: macroeconomics_and_growth, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for education\n",
      "...1    1254\n",
      "Name: education, dtype: int64\n",
      "\n",
      "\n",
      "...Training topic model for communities_and_human_settlements\n",
      "...1    845\n",
      "Name: communities_and_human_settlements, dtype: int64\n",
      "\n",
      "\n",
      "Topic Reports Saved...\n",
      "Topic Binary Saved...\n"
     ]
    }
   ],
   "source": [
    "models, corpai, dicts = train_topic_models(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib  inline \n",
    "# lda_visualization = pyLDAvis.gensim.prepare(models['education'], corpai['education'], dicts['education'], sort_topics=False)\n",
    "# pyLDAvis.display(lda_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use topic models probs as features for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_vector(topic_probs_list):\n",
    "    '''Extract topic probs from gensim data structure'''\n",
    "    data = []\n",
    "    for t in topic_probs_list:\n",
    "        data.append([x[1] for x in t])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<gensim.models.ldamodel.LdaModel object at 0x7f16b9485710>, <gensim.models.ldamodel.LdaModel object at 0x7f16849381d0>, <gensim.models.ldamodel.LdaModel object at 0x7f1684938518>, <gensim.models.ldamodel.LdaModel object at 0x7f1684938400>, <gensim.models.ldamodel.LdaModel object at 0x7f1684938c88>, <gensim.models.ldamodel.LdaModel object at 0x7f1684939400>, <gensim.models.ldamodel.LdaModel object at 0x7f1684939710>, <gensim.models.ldamodel.LdaModel object at 0x7f16849391d0>, <gensim.models.ldamodel.LdaModel object at 0x7f1684939a20>, <gensim.models.ldamodel.LdaModel object at 0x7f168493a470>, <gensim.models.ldamodel.LdaModel object at 0x7f1684936ba8>, <gensim.models.ldamodel.LdaModel object at 0x7f1684936940>, <gensim.models.ldamodel.LdaModel object at 0x7f1684936e10>, <gensim.models.ldamodel.LdaModel object at 0x7f1684938be0>, <gensim.models.ldamodel.LdaModel object at 0x7f16ec4926a0>, <gensim.models.ldamodel.LdaModel object at 0x7f16b9485240>, <gensim.models.ldamodel.LdaModel object at 0x7f1684933dd8>, <gensim.models.ldamodel.LdaModel object at 0x7f16b94854a8>, <gensim.models.ldamodel.LdaModel object at 0x7f1684934898>, <gensim.models.ldamodel.LdaModel object at 0x7f1684934390>, <gensim.models.ldamodel.LdaModel object at 0x7f1684934780>, <gensim.models.ldamodel.LdaModel object at 0x7f1684934eb8>, <gensim.models.ldamodel.LdaModel object at 0x7f1684935da0>, <gensim.models.ldamodel.LdaModel object at 0x7f16849356a0>])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_topics(res):\n",
    "\n",
    "    if len(res[0]) != 3:\n",
    "        zero_found = False\n",
    "        one_found = False\n",
    "        two_found = False\n",
    "              \n",
    "        for x, i in enumerate(res[0][:][:][:]):\n",
    "            if int(i[0]) == 0:\n",
    "                zero_found = True\n",
    "                pass\n",
    "            elif i[0] == 1:\n",
    "                one_found = True\n",
    "                pass\n",
    "            elif i[0] == 2:\n",
    "                two_found = True\n",
    "                pass\n",
    "            \n",
    "        if zero_found == False:\n",
    "            topic_prob = (0, 0.0)\n",
    "            res[0].insert(0, topic_prob)\n",
    "\n",
    "        if one_found == False:\n",
    "            topic_prob = (1, 0.0)\n",
    "            res[0].insert(1, topic_prob)\n",
    "\n",
    "        if two_found == False:\n",
    "            topic_prob = (2, 0.0)\n",
    "            res[0].insert(2, topic_prob)\n",
    "        return res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df[['topic_processed_text']][:].values:\n",
    "#     ids_list = [models['water'].id2word.doc2bow(y) for y in x]\n",
    "#     res = tp[ids_list]\n",
    "# #     print(list(res))\n",
    "#     res = fix_topics(list(res))\n",
    "    \n",
    "#     topic_data = np.array(topic_vector(res))\n",
    "#     i_topic_data_df = pd.DataFrame(topic_data, columns=['topic_{}_{}'.format(name, i) for i in range(topic_data.shape[1])])\n",
    "\n",
    "# #     print(topic_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   topic_infrastructure_economics_and_finance_0  \\\n",
       " 0                                      0.378965   \n",
       " \n",
       "    topic_infrastructure_economics_and_finance_1  \\\n",
       " 0                                      0.051961   \n",
       " \n",
       "    topic_infrastructure_economics_and_finance_2  \n",
       " 0                                      0.569074  ]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... infrastructure_economics_and_finance\n",
      "... public_sector_development\n",
      "... information_and_communication_technologies\n",
      "... poverty_reduction\n",
      "... social_development\n",
      "... conflict_and_development\n",
      "... governance\n",
      "... energy_and_environment\n",
      "... science_and_technology_development\n",
      "... health_and_nutrition_and_population\n"
     ]
    }
   ],
   "source": [
    "# get probs for all topics for all documents \n",
    "topics_list = []\n",
    "for tp, name in zip(models.values(), models.keys()):\n",
    "    print('...',name)   \n",
    "    \n",
    "    '''\n",
    "    for every model:\n",
    "        for each row\n",
    "            get probs and convert to list\n",
    "            put list into df\n",
    "            add df to a list of dfs\n",
    "\n",
    "    concat all the dfs in the lists into a single df (3)\n",
    "    add new df to existing dataframe \n",
    "    \n",
    "    '''\n",
    "    for row in df[['topic_processed_text']].values:\n",
    "        topic_data = np.array(topic_vector(fix_topics(list(tp[[tp.id2word.doc2bow(tokens) for tokens in row]]))))\n",
    "    \n",
    "    i_topic_data_df = pd.DataFrame(topic_data, columns=['topic_{}_{}'.format(name, i) for i in range(topic_data.shape[1])])    \n",
    "    topics_list.append(i_topic_data_df)\n",
    "    \n",
    "topic_data_df = pd.concat(topics_list, axis=1)\n",
    "df = pd.concat([df, topic_data_df], axis=1)\n",
    "print('Probs added to dataframe')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Average word length as feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word_len(text):\n",
    "    #tokenize\n",
    "    try:\n",
    "        #Calculate the average len of the words\n",
    "        sum_len = sum([len(x) for x in text])        \n",
    "        return sum_len / len(text)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_word_len'] = df.processed_text.apply(get_average_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Word Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.processed_text.apply(get_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Document length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_len(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_len'] = df.doc_text.apply(get_doc_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Capatilization Percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_capatilization_perc(text): \n",
    "    text = text.replace(\" \", \"\")\n",
    "    try:\n",
    "        is_upper = 0.0\n",
    "        is_lower = 0.0\n",
    "        for x in text:\n",
    "            if x.isupper():\n",
    "                is_upper+=1\n",
    "            elif x.islower():\n",
    "                is_lower+=1\n",
    "        return ((is_upper / len(text)) * 100)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percentage_text_uppercase'] = df.doc_text.apply(check_capatilization_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Count Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['process_vec'] = df.processed_text.apply(lambda x: ' '.join(x))\n",
    "vec = CountVectorizer(stop_words='english', strip_accents='ascii', max_features=1000)\n",
    "vec.fit(df.process_vec.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Scale Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLS = ['doc_len', 'average_word_len', 'percentage_text_uppercase', 'word_count'] + list(topic_data_df.columns)\n",
    "norm = Normalizer()\n",
    "norm.fit(df[NUMERIC_COLS].fillna(0.0).replace([np.inf, -np.inf], 0.0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vectors\n",
    "pickle.dump(vec, open(os.path.join('./countvec/', 'model_{}.pkl'.format('doc_text')), 'wb'))\n",
    "pickle.dump(vec, open(os.path.join('./countvec/', 'model_{}.pkl'.format('norm')), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_all = np.arange(df.shape[0])\n",
    "indices = {'train': idx_all}\n",
    "datasets = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge features into one set\n",
    "for name, idx in indices.items():\n",
    "    dftmp = df.iloc[idx].fillna(0.0).replace([np.inf, -np.inf], 0.0)\n",
    "    \n",
    "    data = dftmp[list(topics)].values\n",
    "    \n",
    "    a_f = norm.transform(dftmp[NUMERIC_COLS].values)\n",
    "    c_vec = vec.transform(dftmp['process_vec'].fillna('').values).toarray()\n",
    "    datasets[name] = np.hstack([data, a_f, c_vec])\n",
    "    datasets[name][np.isinf(datasets[name])] = 0.0\n",
    "    \n",
    "dataset_cols = list(topics) + NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "train_cols = NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "\n",
    "print(\"Total features on dataset: \", len(dataset_cols))\n",
    "print(\"Total training features: \", len(train_cols))\n",
    "\n",
    "#ensure all features headings are of type string\n",
    "dataset_cols = [str(x) for x in dataset_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "for name, data in datasets.items():\n",
    "        print('...', name)\n",
    "        pd.DataFrame(data, columns=dataset_cols).to_parquet('./{}.parquet'.format(name), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(df)\n",
    "# del(df_values)\n",
    "# del(df_labels)\n",
    "# del(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet('./train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "\n",
    "def train_model(df):\n",
    "    \n",
    "    print('Train Set Size: ' , (len(df) * .8))\n",
    "    print('Test Set Size: ' , (len(df) * .2))\n",
    "    \n",
    "    for label in list(topics):\n",
    "        print('------- {} -------'.format('Training RF for ' + label))\n",
    "        X = df[train_cols]\n",
    "        y = df[label]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019, stratify=y)\n",
    "        \n",
    "        clf = BaggingClassifierPU(RandomForestClassifier(n_estimators=30, max_depth=4, random_state=2019),\n",
    "                                  n_estimators=50, n_jobs=-1, max_samples=list(y_train).count(1))\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Save model to local directory\n",
    "        with open('./classifiers/' + label + '.pkl', 'wb') as fl:\n",
    "            pickle.dump(clf, fl)\n",
    "         \n",
    "        classifiers[label] = clf\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        print('...F1 Score:', f1_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "train_model(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = '../wb-publications-data/test_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probs for all topics for all documents \n",
    "topics_list_v = []\n",
    "for tp, name in zip(models.values(), models.keys()):\n",
    "    \n",
    "    print('...',name)\n",
    "    topic_data = np.array(topic_vector(tp[[tp.id2word.doc2bow(tokens) for tokens in df.topic_processed_text.values]]))\n",
    "\n",
    "#     print(topic_data.shape)\n",
    "\n",
    "    i_topic_data_df = pd.DataFrame(topic_data, \n",
    "                                   columns=['topic_{}_{}'.format(name, i) for i in range(topic_data.shape[1])])\n",
    "    topics_list_v.append(i_topic_data_df)\n",
    "\n",
    "topic_data_df_v = pd.concat(topics_list_v, axis=1)\n",
    "df_test = pd.concat([df_test.reset_index(), topic_data_df_v], axis=1).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocess_text(df_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['average_word_len'] = df_test.processed_text.apply(get_average_word_len)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['word_count'] = df_test.processed_text.apply(get_word_count)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['doc_len'] = df_test.doc_text.apply(get_doc_len)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['percentage_text_uppercase'] = df_test.doc_text.apply(check_capatilization_perc)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['process_vec'] = df_test.processed_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxv_all = np.arange(df_test.shape[0])\n",
    "indices = {'validation': idxv_all}\n",
    "datasets = {}\n",
    "\n",
    "for name, idxv in indices.items():\n",
    "    #merge features into one set\n",
    "    dfvtmp = df_test.iloc[idxv].fillna(0.0).replace([np.inf, -np.inf], 0.0)            \n",
    "    a_f_v = norm.transform(dfvtmp[NUMERIC_COLS].values)\n",
    "    c_vec_v = vec.transform(dfvtmp['process_vec'].fillna('').values).toarray()\n",
    "    datasets[name] = np.hstack([a_f_v, c_vec_v])\n",
    "    datasets[name][np.isinf(datasets[name])] = 0.0\n",
    "    \n",
    "dataset_v_cols = NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "dataset_v_cols = [str(x) for x in dataset_v_cols] \n",
    "\n",
    "print(len(dataset_v_cols))\n",
    "pd.DataFrame(datasets['validation'], columns=dataset_v_cols).to_parquet('./{}.parquet'.format('validation'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_parquet('./validation.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['row_id',\n",
    "            'information_and_communication_technologies',\n",
    "            'governance',\n",
    "            'urban_development',\n",
    "            'law_and_development',\n",
    "            'public_sector_development',\n",
    "            'agriculture',\n",
    "            'communities_and_human_settlements',\n",
    "            'health_and_nutrition_and_population',\n",
    "            'culture_and_development',\n",
    "            'social_protections_and_labor',\n",
    "            'international_economics_and_trade',\n",
    "            'conflict_and_development',\n",
    "            'science_and_technology_development',\n",
    "            'rural_development',\n",
    "            'poverty_reduction',\n",
    "            'social_development',\n",
    "            'education',\n",
    "            'transport',\n",
    "            'gender',\n",
    "            'infrastructure_economics_and_finance',\n",
    "            'energy_and_environment',\n",
    "            'finance_and_development',\n",
    "            'macroeconomics_and_growth', \n",
    "            'water'\n",
    "           ]\n",
    "\n",
    "output_df = pd.DataFrame(columns=out_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../wb-publications-data/submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in submission_df.columns:\n",
    "    if topic in topics:       \n",
    "        with open('./classifiers/' + topic + '.pkl', 'rb') as pickle_file:\n",
    "            forest_model = pickle.load(pickle_file)\n",
    "        submission_df[topic] = forest_model.predict(df_val[:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = submission_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
