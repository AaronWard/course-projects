{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Capstone Project - Notebook 3\n",
    "- Clean text (Tokenize, lower, remove stopwords, lemmentize, stem etc)\n",
    "- CountVectorizer on 10000 words for features\n",
    "- Use Average word length as feature\n",
    "- length of document\n",
    "- Scale Features\n",
    "- Sentiment and subjectivity of document text\n",
    "- Do not downsample training data \n",
    "- Train models for each topic:\n",
    "    - Linear SVC\n",
    "    - Logistic Regression \n",
    "\n",
    "\"Your goal is to predict the topic(s) of publications from the World Bank, where there are 24 possible topics. <br>\n",
    "You will be given the first six pages of text from each dociument. <br>Each document has at least one topic and can have multiple topics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing and Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "TRAINING_DATA = '../../wb-publications-data/train_values.csv'\n",
    "TRAINING_LABEL = '../../wb-publications-data/train_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = pd.read_csv(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(TRAINING_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_values, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample data to text out preprocessing\n",
    "df = df_all[:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "     return [lemmatizer.lemmatize(word) for word in text]\n",
    "        \n",
    "def preprocess_text(df):\n",
    "    exclude = set(string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update((\"develop\", \"develops\", \"developing\", \"busi\", \"business\", \"businesses\", \"program\", \"programs\"))\n",
    "    \n",
    "    #Preprocess text column\n",
    "    df['processed_text'] = df.doc_text.str.replace(r'\\d+', '')                                  #Remove number\n",
    "    df['processed_text'] = df.processed_text.str.lower()                                        #lower\n",
    "    df['processed_text'] = df.processed_text.str.replace('http\\S+|www.\\S+', '', case=False)     #Remove website links\n",
    "    df[\"processed_text\"] = df.processed_text.str.replace('[{}]'.format(string.punctuation), '') #Remove all punctations\n",
    "\n",
    "    df['processed_text'] = df.apply(lambda row: word_tokenize(row[\"processed_text\"]), axis=1)\n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.rstrip() for word in x])                       #Remove white spaces\n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.replace('\\n', ' ') for word in x])             #Remove literal blackslashes  \n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.replace(r\"\\s\\s+\",' ') for word in x])          #Remove White spaces \n",
    "    df['processed_text'] = df.processed_text.apply(lambda x:[word.strip() for word in x if len(word) > 4])       #Remove spaces out words and acronyms\n",
    "\n",
    "    #Remove stop words \n",
    "    df[\"topic_processed_text\"] = df.processed_text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lambda x: [word for word in x if word not in exclude])\n",
    "    \n",
    "    #Lemmantize Words\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lemmatize_text)\n",
    "    \n",
    "    #Stemming\n",
    "    df['topic_processed_text'] = df.topic_processed_text.apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>topic_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...</td>\n",
       "      <td>[findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...</td>\n",
       "      <td>[find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>[decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...</td>\n",
       "      <td>[decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...</td>\n",
       "      <td>[taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...</td>\n",
       "      <td>[take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WPS5836\\n\\n\\nPolicy Research Working Paper     ...</td>\n",
       "      <td>[policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...</td>\n",
       "      <td>[polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1                                   WPS39...</td>\n",
       "      <td>[relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...</td>\n",
       "      <td>[rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              doc_text  \\\n",
       "0  84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...   \n",
       "1                                                                                                  ...   \n",
       "2                             78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...   \n",
       "3                                                   WPS5836\\n\\n\\nPolicy Research Working Paper     ...   \n",
       "4                                                         1                                   WPS39...   \n",
       "\n",
       "                                                                                        processed_text  \\\n",
       "0  [findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...   \n",
       "1  [decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...   \n",
       "2  [taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...   \n",
       "3  [policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...   \n",
       "4  [relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...   \n",
       "\n",
       "                                                                                  topic_processed_text  \n",
       "0  [find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...  \n",
       "1  [decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...  \n",
       "2  [take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...  \n",
       "3  [polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...  \n",
       "4  [rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['doc_text', 'processed_text', 'topic_processed_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create names for each model based on label names\n",
    "topics = []\n",
    "for col in df_labels.columns:\n",
    "    if col != 'row_id':\n",
    "        topics.append(str(col))\n",
    "topics = set(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>row_id</th>\n",
       "      <th>information_and_communication_technologies</th>\n",
       "      <th>governance</th>\n",
       "      <th>urban_development</th>\n",
       "      <th>law_and_development</th>\n",
       "      <th>public_sector_development</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>communities_and_human_settlements</th>\n",
       "      <th>health_and_nutrition_and_population</th>\n",
       "      <th>culture_and_development</th>\n",
       "      <th>social_protections_and_labor</th>\n",
       "      <th>international_economics_and_trade</th>\n",
       "      <th>conflict_and_development</th>\n",
       "      <th>science_and_technology_development</th>\n",
       "      <th>rural_development</th>\n",
       "      <th>poverty_reduction</th>\n",
       "      <th>social_development</th>\n",
       "      <th>education</th>\n",
       "      <th>transport</th>\n",
       "      <th>gender</th>\n",
       "      <th>infrastructure_economics_and_finance</th>\n",
       "      <th>energy_and_environment</th>\n",
       "      <th>finance_and_development</th>\n",
       "      <th>macroeconomics_and_growth</th>\n",
       "      <th>water</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>topic_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...</td>\n",
       "      <td>[find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...</td>\n",
       "      <td>[decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...</td>\n",
       "      <td>[take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WPS5836\\n\\n\\nPolicy Research Working Paper     ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...</td>\n",
       "      <td>[polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1                                   WPS39...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...</td>\n",
       "      <td>[rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       2   \n",
       "3       3   \n",
       "4       4   \n",
       "\n",
       "                                                                                              doc_text  \\\n",
       "0  84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...   \n",
       "1                                                                                                  ...   \n",
       "2                             78156\\n\\n\\n\\n\\nRisk Taking: A Corporate\\nGovernance Perspective\\nACKN...   \n",
       "3                                                   WPS5836\\n\\n\\nPolicy Research Working Paper     ...   \n",
       "4                                                         1                                   WPS39...   \n",
       "\n",
       "   row_id  information_and_communication_technologies  governance  \\\n",
       "0       0                                           1           0   \n",
       "1       1                                           0           0   \n",
       "2       2                                           0           0   \n",
       "3       3                                           0           0   \n",
       "4       4                                           0           0   \n",
       "\n",
       "   urban_development  law_and_development  public_sector_development  \\\n",
       "0                  0                    0                          0   \n",
       "1                  0                    0                          0   \n",
       "2                  0                    0                          0   \n",
       "3                  0                    0                          0   \n",
       "4                  0                    1                          0   \n",
       "\n",
       "   agriculture  communities_and_human_settlements  \\\n",
       "0            0                                  0   \n",
       "1            0                                  0   \n",
       "2            0                                  0   \n",
       "3            0                                  0   \n",
       "4            0                                  0   \n",
       "\n",
       "   health_and_nutrition_and_population  culture_and_development  \\\n",
       "0                                    1                        0   \n",
       "1                                    0                        0   \n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        0   \n",
       "\n",
       "   social_protections_and_labor  international_economics_and_trade  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  1   \n",
       "2                             1                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  1   \n",
       "\n",
       "   conflict_and_development  science_and_technology_development  \\\n",
       "0                         0                                   0   \n",
       "1                         0                                   0   \n",
       "2                         0                                   0   \n",
       "3                         0                                   0   \n",
       "4                         0                                   0   \n",
       "\n",
       "   rural_development  poverty_reduction  social_development  education  \\\n",
       "0                  0                  1                   0          0   \n",
       "1                  0                  0                   0          0   \n",
       "2                  0                  0                   0          0   \n",
       "3                  0                  0                   0          0   \n",
       "4                  0                  0                   0          0   \n",
       "\n",
       "   transport  gender  infrastructure_economics_and_finance  \\\n",
       "0          0       0                                     0   \n",
       "1          0       0                                     0   \n",
       "2          0       0                                     0   \n",
       "3          0       0                                     0   \n",
       "4          0       0                                     0   \n",
       "\n",
       "   energy_and_environment  finance_and_development  macroeconomics_and_growth  \\\n",
       "0                       0                        1                          1   \n",
       "1                       0                        1                          1   \n",
       "2                       0                        1                          0   \n",
       "3                       0                        1                          0   \n",
       "4                       0                        0                          1   \n",
       "\n",
       "   water  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                        processed_text  \\\n",
       "0  [findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...   \n",
       "1  [decpg, daily, economics, financial, market, commentary, allen, dennis, sanket, mohapatra, riord...   \n",
       "2  [taking, corporate, governance, perspective, acknowledgements, genesis, teaching, materials, fin...   \n",
       "3  [policy, research, working, paper, above, below, lending, hungary, banai, kirly, mrton, world, e...   \n",
       "4  [relative, importance, global, agricultural, subsidies, market, access, anderson, martin, ernest...   \n",
       "\n",
       "                                                                                  topic_processed_text  \n",
       "0  [find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...  \n",
       "1  [decpg, daili, econom, financi, market, commentari, allen, denni, sanket, mohapatra, riordan, yo...  \n",
       "2  [take, corpor, govern, perspect, acknowledg, genesi, teach, materi, final, product, effort, cont...  \n",
       "3  [polici, research, work, paper, lend, hungari, banai, kirli, mrton, world, europ, central, regio...  \n",
       "4  [rel, import, global, agricultur, subsidi, market, access, anderson, martin, ernesto, valenzuela...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Average word length as feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word_len(text):\n",
    "    #tokenize\n",
    "    try:\n",
    "        #Calculate the average len of the words\n",
    "        sum_len = sum([len(x) for x in text])        \n",
    "        return sum_len / len(text)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_word_len'] = df.processed_text.apply(get_average_word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Word Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.processed_text.apply(get_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Document length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_len(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_len'] = df.doc_text.apply(get_doc_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Capatilization Percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_capatilization_perc(text): \n",
    "    text = text.replace(\" \", \"\")\n",
    "    try:\n",
    "        is_upper = 0.0\n",
    "        is_lower = 0.0\n",
    "        for x in text:\n",
    "            if x.isupper():\n",
    "                is_upper+=1\n",
    "            elif x.islower():\n",
    "                is_lower+=1\n",
    "        return ((is_upper / len(text)) * 100)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percentage_text_uppercase'] = df.doc_text.apply(check_capatilization_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>row_id</th>\n",
       "      <th>information_and_communication_technologies</th>\n",
       "      <th>governance</th>\n",
       "      <th>urban_development</th>\n",
       "      <th>law_and_development</th>\n",
       "      <th>public_sector_development</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>communities_and_human_settlements</th>\n",
       "      <th>health_and_nutrition_and_population</th>\n",
       "      <th>culture_and_development</th>\n",
       "      <th>social_protections_and_labor</th>\n",
       "      <th>international_economics_and_trade</th>\n",
       "      <th>conflict_and_development</th>\n",
       "      <th>science_and_technology_development</th>\n",
       "      <th>rural_development</th>\n",
       "      <th>poverty_reduction</th>\n",
       "      <th>social_development</th>\n",
       "      <th>education</th>\n",
       "      <th>transport</th>\n",
       "      <th>gender</th>\n",
       "      <th>infrastructure_economics_and_finance</th>\n",
       "      <th>energy_and_environment</th>\n",
       "      <th>finance_and_development</th>\n",
       "      <th>macroeconomics_and_growth</th>\n",
       "      <th>water</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>topic_processed_text</th>\n",
       "      <th>average_word_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>percentage_text_uppercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...</td>\n",
       "      <td>[find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...</td>\n",
       "      <td>7.622807</td>\n",
       "      <td>342</td>\n",
       "      <td>19820</td>\n",
       "      <td>5.309182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  \\\n",
       "0       0   \n",
       "\n",
       "                                                                                              doc_text  \\\n",
       "0  84327 v2\\nThe findings, interpretations, and conclusions expressed in this report do not\\nnecess...   \n",
       "\n",
       "   row_id  information_and_communication_technologies  governance  \\\n",
       "0       0                                           1           0   \n",
       "\n",
       "   urban_development  law_and_development  public_sector_development  \\\n",
       "0                  0                    0                          0   \n",
       "\n",
       "   agriculture  communities_and_human_settlements  \\\n",
       "0            0                                  0   \n",
       "\n",
       "   health_and_nutrition_and_population  culture_and_development  \\\n",
       "0                                    1                        0   \n",
       "\n",
       "   social_protections_and_labor  international_economics_and_trade  \\\n",
       "0                             0                                  0   \n",
       "\n",
       "   conflict_and_development  science_and_technology_development  \\\n",
       "0                         0                                   0   \n",
       "\n",
       "   rural_development  poverty_reduction  social_development  education  \\\n",
       "0                  0                  1                   0          0   \n",
       "\n",
       "   transport  gender  infrastructure_economics_and_finance  \\\n",
       "0          0       0                                     0   \n",
       "\n",
       "   energy_and_environment  finance_and_development  macroeconomics_and_growth  \\\n",
       "0                       0                        1                          1   \n",
       "\n",
       "   water  \\\n",
       "0      0   \n",
       "\n",
       "                                                                                        processed_text  \\\n",
       "0  [findings, interpretations, conclusions, expressed, report, necessarily, reflect, views, positio...   \n",
       "\n",
       "                                                                                  topic_processed_text  \\\n",
       "0  [find, interpret, conclus, express, report, necessarili, reflect, view, posit, execut, director,...   \n",
       "\n",
       "   average_word_len  word_count  doc_len  percentage_text_uppercase  \n",
       "0          7.622807         342    19820                   5.309182  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def get_polarity_sent(text):\n",
    "    try:\n",
    "        text = TextBlob(text)\n",
    "        score = (text.sentiment.polarity + 1) / 2 #Bring score in a range between 0 and 1 \n",
    "        return score\n",
    "    except:\n",
    "        return 0.5 #Return a neutral response\n",
    "\n",
    "def get_subjectivity_sent(text):\n",
    "    try:\n",
    "        text = TextBlob(text)\n",
    "        return text.sentiment.subjectivity\n",
    "    except:\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['process_vec'] = df.processed_text.apply(lambda x: ' '.join(x)) #Possible change this to lemmentize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_polarity'] = df.doc_text.apply(get_polarity_sent)\n",
    "df['sentiment_subjectivity'] = df.doc_text.apply(get_subjectivity_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Count Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=10000, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents='ascii', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', strip_accents='ascii', max_features=10000)\n",
    "vec.fit(df.process_vec.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Scale Numeric Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer(copy=True, norm='l2')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERIC_COLS = ['doc_len', 'average_word_len', 'percentage_text_uppercase', 'word_count', 'sentiment_polarity', 'sentiment_subjectivity']\n",
    "norm = Normalizer()\n",
    "norm.fit(df[NUMERIC_COLS].fillna(0.0).replace([np.inf, -np.inf], 0.0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vectors\n",
    "pickle.dump(vec, open(os.path.join('./countvec/', 'model_{}.pkl'.format('doc_text')), 'wb'))\n",
    "pickle.dump(vec, open(os.path.join('./countvec/', 'model_{}.pkl'.format('norm')), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_all = np.arange(df.shape[0])\n",
    "indices = {'train': idx_all}\n",
    "datasets = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features on dataset:  10030\n",
      "Total training features:  10006\n"
     ]
    }
   ],
   "source": [
    "#merge features into one set\n",
    "for name, idx in indices.items():\n",
    "    dftmp = df.iloc[idx].fillna(0.0).replace([np.inf, -np.inf], 0.0)\n",
    "    \n",
    "    data = dftmp[list(topics)].values\n",
    "    \n",
    "    a_f = norm.transform(dftmp[NUMERIC_COLS].values)\n",
    "    c_vec = vec.transform(dftmp['process_vec'].fillna('').values).toarray()\n",
    "    datasets[name] = np.hstack([data, a_f, c_vec])\n",
    "    datasets[name][np.isinf(datasets[name])] = 0.0\n",
    "    \n",
    "dataset_cols = list(topics) + NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "train_cols = NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "\n",
    "print(\"Total features on dataset: \", len(dataset_cols))\n",
    "print(\"Total training features: \", len(train_cols))\n",
    "\n",
    "#ensure all features headings are of type string\n",
    "dataset_cols = [str(x) for x in dataset_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... train\n"
     ]
    }
   ],
   "source": [
    "# Save Dataset\n",
    "for name, data in datasets.items():\n",
    "        print('...', name)\n",
    "        pd.DataFrame(data, columns=dataset_cols).to_parquet('./{}.parquet'.format(name), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet('./train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water</th>\n",
       "      <th>macroeconomics_and_growth</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>law_and_development</th>\n",
       "      <th>infrastructure_economics_and_finance</th>\n",
       "      <th>health_and_nutrition_and_population</th>\n",
       "      <th>international_economics_and_trade</th>\n",
       "      <th>communities_and_human_settlements</th>\n",
       "      <th>public_sector_development</th>\n",
       "      <th>culture_and_development</th>\n",
       "      <th>energy_and_environment</th>\n",
       "      <th>science_and_technology_development</th>\n",
       "      <th>gender</th>\n",
       "      <th>conflict_and_development</th>\n",
       "      <th>governance</th>\n",
       "      <th>education</th>\n",
       "      <th>information_and_communication_technologies</th>\n",
       "      <th>social_protections_and_labor</th>\n",
       "      <th>social_development</th>\n",
       "      <th>urban_development</th>\n",
       "      <th>transport</th>\n",
       "      <th>rural_development</th>\n",
       "      <th>finance_and_development</th>\n",
       "      <th>poverty_reduction</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>...</th>\n",
       "      <th>token_youre</th>\n",
       "      <th>token_youth</th>\n",
       "      <th>token_youths</th>\n",
       "      <th>token_yugoslav</th>\n",
       "      <th>token_yugoslavia</th>\n",
       "      <th>token_yunnan</th>\n",
       "      <th>token_yusuf</th>\n",
       "      <th>token_zaidi</th>\n",
       "      <th>token_zaman</th>\n",
       "      <th>token_zambia</th>\n",
       "      <th>token_zambian</th>\n",
       "      <th>token_zambias</th>\n",
       "      <th>token_zanzibar</th>\n",
       "      <th>token_zation</th>\n",
       "      <th>token_zealand</th>\n",
       "      <th>token_zeroduty</th>\n",
       "      <th>token_zhang</th>\n",
       "      <th>token_zimbabwe</th>\n",
       "      <th>token_zimbabwes</th>\n",
       "      <th>token_zingales</th>\n",
       "      <th>token_zoellick</th>\n",
       "      <th>token_zones</th>\n",
       "      <th>token_zoning</th>\n",
       "      <th>token_zscore</th>\n",
       "      <th>token_zusammenarbeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  10030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   water  macroeconomics_and_growth  agriculture  law_and_development  \\\n",
       "0    0.0                        1.0          0.0                  0.0   \n",
       "1    0.0                        1.0          0.0                  0.0   \n",
       "2    0.0                        0.0          0.0                  0.0   \n",
       "3    0.0                        0.0          0.0                  0.0   \n",
       "4    0.0                        1.0          0.0                  1.0   \n",
       "\n",
       "   infrastructure_economics_and_finance  health_and_nutrition_and_population  \\\n",
       "0                                   0.0                                  1.0   \n",
       "1                                   0.0                                  0.0   \n",
       "2                                   0.0                                  0.0   \n",
       "3                                   0.0                                  0.0   \n",
       "4                                   0.0                                  0.0   \n",
       "\n",
       "   international_economics_and_trade  communities_and_human_settlements  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                1.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                1.0                                0.0   \n",
       "\n",
       "   public_sector_development  culture_and_development  energy_and_environment  \\\n",
       "0                        0.0                      0.0                     0.0   \n",
       "1                        0.0                      0.0                     0.0   \n",
       "2                        0.0                      0.0                     0.0   \n",
       "3                        0.0                      0.0                     0.0   \n",
       "4                        0.0                      0.0                     0.0   \n",
       "\n",
       "   science_and_technology_development  gender  conflict_and_development  \\\n",
       "0                                 0.0     0.0                       0.0   \n",
       "1                                 0.0     0.0                       0.0   \n",
       "2                                 0.0     0.0                       0.0   \n",
       "3                                 0.0     0.0                       0.0   \n",
       "4                                 0.0     0.0                       0.0   \n",
       "\n",
       "   governance  education  information_and_communication_technologies  \\\n",
       "0         0.0        0.0                                         1.0   \n",
       "1         0.0        0.0                                         0.0   \n",
       "2         0.0        0.0                                         0.0   \n",
       "3         0.0        0.0                                         0.0   \n",
       "4         0.0        0.0                                         0.0   \n",
       "\n",
       "   social_protections_and_labor  social_development  urban_development  \\\n",
       "0                           0.0                 0.0                0.0   \n",
       "1                           0.0                 0.0                0.0   \n",
       "2                           1.0                 0.0                0.0   \n",
       "3                           0.0                 0.0                0.0   \n",
       "4                           0.0                 0.0                0.0   \n",
       "\n",
       "   transport  rural_development  finance_and_development  poverty_reduction  \\\n",
       "0        0.0                0.0                      1.0                1.0   \n",
       "1        0.0                0.0                      1.0                0.0   \n",
       "2        0.0                0.0                      1.0                0.0   \n",
       "3        0.0                0.0                      1.0                0.0   \n",
       "4        0.0                0.0                      0.0                0.0   \n",
       "\n",
       "    doc_len  ...  token_youre  token_youth  token_youths  token_yugoslav  \\\n",
       "0  0.999851  ...          0.0          0.0           0.0             0.0   \n",
       "1  0.997300  ...          0.0          0.0           0.0             0.0   \n",
       "2  0.998429  ...          0.0          0.0           0.0             0.0   \n",
       "3  0.998509  ...          0.0          0.0           0.0             0.0   \n",
       "4  0.997472  ...          0.0          0.0           0.0             0.0   \n",
       "\n",
       "   token_yugoslavia  token_yunnan  token_yusuf  token_zaidi  token_zaman  \\\n",
       "0               0.0           0.0          0.0          0.0          0.0   \n",
       "1               0.0           0.0          0.0          0.0          0.0   \n",
       "2               0.0           0.0          0.0          0.0          0.0   \n",
       "3               0.0           0.0          0.0          0.0          0.0   \n",
       "4               0.0           0.0          0.0          0.0          0.0   \n",
       "\n",
       "   token_zambia  token_zambian  token_zambias  token_zanzibar  token_zation  \\\n",
       "0           0.0            0.0            0.0             0.0           0.0   \n",
       "1           0.0            0.0            0.0             0.0           0.0   \n",
       "2           0.0            0.0            0.0             0.0           0.0   \n",
       "3           0.0            0.0            0.0             0.0           0.0   \n",
       "4           0.0            0.0            0.0             0.0           0.0   \n",
       "\n",
       "   token_zealand  token_zeroduty  token_zhang  token_zimbabwe  \\\n",
       "0            0.0             0.0          0.0             0.0   \n",
       "1            0.0             0.0          0.0             0.0   \n",
       "2            0.0             0.0          0.0             0.0   \n",
       "3            0.0             0.0          0.0             0.0   \n",
       "4            0.0             0.0          0.0             0.0   \n",
       "\n",
       "   token_zimbabwes  token_zingales  token_zoellick  token_zones  token_zoning  \\\n",
       "0              0.0             0.0             0.0          0.0           0.0   \n",
       "1              0.0             0.0             0.0          0.0           0.0   \n",
       "2              0.0             0.0             0.0          0.0           0.0   \n",
       "3              0.0             0.0             0.0          0.0           0.0   \n",
       "4              0.0             0.0             0.0          0.0           0.0   \n",
       "\n",
       "   token_zscore  token_zusammenarbeit  \n",
       "0           0.0                   0.0  \n",
       "1           0.0                   0.0  \n",
       "2           0.0                   0.0  \n",
       "3           0.0                   0.0  \n",
       "4           0.0                   0.0  \n",
       "\n",
       "[5 rows x 10030 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size:  14949.6\n",
      "Test Set Size:  3737.4\n",
      "------- Training SVC for water -------\n",
      "...F1 Score: 0.920545746388443\n",
      "------- Training SVC for macroeconomics_and_growth -------\n",
      "...F1 Score: 0.6958266452648475\n",
      "------- Training SVC for agriculture -------\n",
      "...F1 Score: 0.9253611556982343\n",
      "------- Training SVC for law_and_development -------\n",
      "...F1 Score: 0.8394863563402889\n",
      "------- Training SVC for infrastructure_economics_and_finance -------\n",
      "...F1 Score: 0.9839486356340289\n",
      "------- Training SVC for health_and_nutrition_and_population -------\n",
      "...F1 Score: 0.8352059925093633\n",
      "------- Training SVC for international_economics_and_trade -------\n",
      "...F1 Score: 0.8849652220438737\n",
      "------- Training SVC for communities_and_human_settlements -------\n",
      "...F1 Score: 0.920813269127876\n",
      "------- Training SVC for public_sector_development -------\n",
      "...F1 Score: 0.8191546281433922\n",
      "------- Training SVC for culture_and_development -------\n",
      "...F1 Score: 0.9745853397538791\n",
      "------- Training SVC for energy_and_environment -------\n",
      "...F1 Score: 0.8515248796147673\n",
      "------- Training SVC for science_and_technology_development -------\n",
      "...F1 Score: 0.9234884965222044\n",
      "------- Training SVC for gender -------\n",
      "...F1 Score: 0.9398073836276083\n",
      "------- Training SVC for conflict_and_development -------\n",
      "...F1 Score: 0.9357945425361156\n",
      "------- Training SVC for governance -------\n",
      "...F1 Score: 0.8694489031567684\n",
      "------- Training SVC for education -------\n",
      "...F1 Score: 0.8889780631353665\n",
      "------- Training SVC for information_and_communication_technologies -------\n",
      "...F1 Score: 0.9373996789727127\n",
      "------- Training SVC for social_protections_and_labor -------\n",
      "...F1 Score: 0.8587479935794543\n",
      "------- Training SVC for social_development -------\n",
      "...F1 Score: 0.8734617442482611\n",
      "------- Training SVC for urban_development -------\n",
      "...F1 Score: 0.904226859283039\n",
      "------- Training SVC for transport -------\n",
      "...F1 Score: 0.9157303370786517\n",
      "------- Training SVC for rural_development -------\n",
      "...F1 Score: 0.8622257891920815\n",
      "------- Training SVC for finance_and_development -------\n",
      "...F1 Score: 0.7388978063135366\n",
      "------- Training SVC for poverty_reduction -------\n",
      "...F1 Score: 0.8413590155163189\n"
     ]
    }
   ],
   "source": [
    "def train_svc_model(df):\n",
    "    \n",
    "    print('Train Set Size: ' , (len(df) * .8))\n",
    "    print('Test Set Size: ' , (len(df) * .2))\n",
    "                  \n",
    "    \n",
    "    for label in list(topics):\n",
    "        print('------- {} -------'.format('Training SVC for ' + label))\n",
    "        X = df[train_cols]\n",
    "        y = df[label]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019, stratify=y)\n",
    "\n",
    "        svc = OneVsRestClassifier(LinearSVC(), n_jobs=-1).fit(X_train, y_train)\n",
    "        # Save model to local directory\n",
    "        with open('./svc_classifiers/' + label + '.pkl', 'wb') as fl:\n",
    "            pickle.dump(svc, fl)\n",
    "             \n",
    "        y_pred = svc.predict(X_test)\n",
    "        print('...F1 Score:', f1_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "train_svc_model(df2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size:  14949.6\n",
      "Test Set Size:  3737.4\n",
      "------- Training Linear Regression for water -------\n",
      "...F1 Score: 0.9590690208667737\n",
      "------- Training Linear Regression for macroeconomics_and_growth -------\n",
      "...F1 Score: 0.7723381487426432\n",
      "------- Training Linear Regression for agriculture -------\n",
      "...F1 Score: 0.9531835205992509\n",
      "------- Training Linear Regression for law_and_development -------\n",
      "...F1 Score: 0.898876404494382\n",
      "------- Training Linear Regression for infrastructure_economics_and_finance -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/award40/anaconda3/envs/dev/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...F1 Score: 0.9884965222043873\n",
      "------- Training Linear Regression for health_and_nutrition_and_population -------\n",
      "...F1 Score: 0.8943285179240236\n",
      "------- Training Linear Regression for international_economics_and_trade -------\n",
      "...F1 Score: 0.9200107009095773\n",
      "------- Training Linear Regression for communities_and_human_settlements -------\n",
      "...F1 Score: 0.9430176565008026\n",
      "------- Training Linear Regression for public_sector_development -------\n",
      "...F1 Score: 0.8908507223113965\n",
      "------- Training Linear Regression for culture_and_development -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/award40/anaconda3/envs/dev/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...F1 Score: 0.9839486356340289\n",
      "------- Training Linear Regression for energy_and_environment -------\n",
      "...F1 Score: 0.9004815409309791\n",
      "------- Training Linear Regression for science_and_technology_development -------\n",
      "...F1 Score: 0.9614767255216693\n",
      "------- Training Linear Regression for gender -------\n",
      "...F1 Score: 0.9652220438737292\n",
      "------- Training Linear Regression for conflict_and_development -------\n",
      "...F1 Score: 0.9665596575708936\n",
      "------- Training Linear Regression for governance -------\n",
      "...F1 Score: 0.9237560192616372\n",
      "------- Training Linear Regression for education -------\n",
      "...F1 Score: 0.9309791332263242\n",
      "------- Training Linear Regression for information_and_communication_technologies -------\n",
      "...F1 Score: 0.9612092027822365\n",
      "------- Training Linear Regression for social_protections_and_labor -------\n",
      "...F1 Score: 0.904226859283039\n",
      "------- Training Linear Regression for social_development -------\n",
      "...F1 Score: 0.9288389513108615\n",
      "------- Training Linear Regression for urban_development -------\n",
      "...F1 Score: 0.9438202247191011\n",
      "------- Training Linear Regression for transport -------\n",
      "...F1 Score: 0.9499732477260567\n",
      "------- Training Linear Regression for rural_development -------\n",
      "...F1 Score: 0.920813269127876\n",
      "------- Training Linear Regression for finance_and_development -------\n",
      "...F1 Score: 0.8127340823970037\n",
      "------- Training Linear Regression for poverty_reduction -------\n",
      "...F1 Score: 0.9002140181915462\n"
     ]
    }
   ],
   "source": [
    "def train_lr_model(df):\n",
    "    \n",
    "    print('Train Set Size: ' , (len(df) * .8))\n",
    "    print('Test Set Size: ' , (len(df) * .2))\n",
    "                  \n",
    "    for label in list(topics):\n",
    "        print('------- {} -------'.format('Training Linear Regression for ' + label))\n",
    "        X = df[train_cols]\n",
    "        y = df[label]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019, stratify=y)\n",
    "\n",
    "        lr = OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1).fit(X_train, y_train)\n",
    "        # Save model to local directory\n",
    "        with open('./lr_classifier/' + label + '.pkl', 'wb') as fl:\n",
    "            pickle.dump(lr, fl)\n",
    "             \n",
    "        y_pred = lr.predict(X_test)\n",
    "        print('...F1 Score:', f1_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "train_lr_model(df2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = '../../wb-publications-data/test_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>doc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EARLY LEARNING PARTNERSHIP\\n\\n\\n\\n\\n E L P\\n                                                   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WPS5739\\n\\n\\nPolicy Research Working Paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WPS7840\\n\\n\\nPolicy Research Working Paper      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       2   \n",
       "3       3   \n",
       "4       4   \n",
       "\n",
       "                                                                                              doc_text  \n",
       "0                                                                                                  ...  \n",
       "1   EARLY LEARNING PARTNERSHIP\\n\\n\\n\\n\\n E L P\\n                                                   ...  \n",
       "2                                                        WPS5739\\n\\n\\nPolicy Research Working Paper...  \n",
       "3                                                  WPS7840\\n\\n\\nPolicy Research Working Paper      ...  \n",
       "4                                                                                                  ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_test = preprocess_text(df_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_test['average_word_len'] = df_test.processed_text.apply(get_average_word_len)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_test['word_count'] = df_test.processed_text.apply(get_word_count)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_test['doc_len'] = df_test.doc_text.apply(get_doc_len)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_test['percentage_text_uppercase'] = df_test.doc_text.apply(check_capatilization_perc)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['process_vec'] = df_test.processed_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment_polarity'] = df_test.doc_text.apply(get_polarity_sent)\n",
    "df_test['sentiment_subjectivity'] = df_test.doc_text.apply(get_subjectivity_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10006\n"
     ]
    }
   ],
   "source": [
    "idxv_all = np.arange(df_test.shape[0])\n",
    "indices = {'validation': idxv_all}\n",
    "datasets = {}\n",
    "\n",
    "for name, idxv in indices.items():\n",
    "    #merge features into one set\n",
    "    dfvtmp = df_test.iloc[idxv].fillna(0.0).replace([np.inf, -np.inf], 0.0)            \n",
    "    a_f_v = norm.transform(dfvtmp[NUMERIC_COLS].values)\n",
    "    c_vec_v = vec.transform(dfvtmp['process_vec'].fillna('').values).toarray()\n",
    "    datasets[name] = np.hstack([a_f_v, c_vec_v])\n",
    "    datasets[name][np.isinf(datasets[name])] = 0.0\n",
    "    \n",
    "dataset_v_cols = NUMERIC_COLS + ['token_' + t for t in list(vec.get_feature_names())]\n",
    "dataset_v_cols = [str(x) for x in dataset_v_cols] \n",
    "\n",
    "print(len(dataset_v_cols))\n",
    "pd.DataFrame(datasets['validation'], columns=dataset_v_cols).to_parquet('./{}.parquet'.format('validation'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_parquet('./validation.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_len</th>\n",
       "      <th>average_word_len</th>\n",
       "      <th>percentage_text_uppercase</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>token_aaditya</th>\n",
       "      <th>token_ababa</th>\n",
       "      <th>token_abandoned</th>\n",
       "      <th>token_abatement</th>\n",
       "      <th>token_abbreviations</th>\n",
       "      <th>token_abdul</th>\n",
       "      <th>token_abidjan</th>\n",
       "      <th>token_abilities</th>\n",
       "      <th>token_ability</th>\n",
       "      <th>token_abolition</th>\n",
       "      <th>token_abortion</th>\n",
       "      <th>token_abovementioned</th>\n",
       "      <th>token_abreast</th>\n",
       "      <th>token_abridged</th>\n",
       "      <th>token_abroad</th>\n",
       "      <th>token_abrupt</th>\n",
       "      <th>token_absence</th>\n",
       "      <th>token_absent</th>\n",
       "      <th>token_absenteeism</th>\n",
       "      <th>...</th>\n",
       "      <th>token_youre</th>\n",
       "      <th>token_youth</th>\n",
       "      <th>token_youths</th>\n",
       "      <th>token_yugoslav</th>\n",
       "      <th>token_yugoslavia</th>\n",
       "      <th>token_yunnan</th>\n",
       "      <th>token_yusuf</th>\n",
       "      <th>token_zaidi</th>\n",
       "      <th>token_zaman</th>\n",
       "      <th>token_zambia</th>\n",
       "      <th>token_zambian</th>\n",
       "      <th>token_zambias</th>\n",
       "      <th>token_zanzibar</th>\n",
       "      <th>token_zation</th>\n",
       "      <th>token_zealand</th>\n",
       "      <th>token_zeroduty</th>\n",
       "      <th>token_zhang</th>\n",
       "      <th>token_zimbabwe</th>\n",
       "      <th>token_zimbabwes</th>\n",
       "      <th>token_zingales</th>\n",
       "      <th>token_zoellick</th>\n",
       "      <th>token_zones</th>\n",
       "      <th>token_zoning</th>\n",
       "      <th>token_zscore</th>\n",
       "      <th>token_zusammenarbeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998931</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.046223</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.054042</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997646</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997490</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.070811</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997350</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.072718</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  10006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_len  average_word_len  percentage_text_uppercase  word_count  \\\n",
       "0  0.998931          0.000373                   0.000218    0.046223   \n",
       "1  0.998538          0.000398                   0.000433    0.054042   \n",
       "2  0.997646          0.000426                   0.000118    0.068571   \n",
       "3  0.997490          0.000413                   0.000111    0.070811   \n",
       "4  0.997350          0.001995                   0.000965    0.072718   \n",
       "\n",
       "   sentiment_polarity  sentiment_subjectivity  token_aaditya  token_ababa  \\\n",
       "0            0.000027                0.000022            0.0          0.0   \n",
       "1            0.000028                0.000016            0.0          0.0   \n",
       "2            0.000027                0.000020            0.0          0.0   \n",
       "3            0.000028                0.000020            0.0          0.0   \n",
       "4            0.000149                0.000089            0.0          0.0   \n",
       "\n",
       "   token_abandoned  token_abatement  token_abbreviations  token_abdul  \\\n",
       "0              0.0              0.0                  0.0          0.0   \n",
       "1              0.0              0.0                  0.0          0.0   \n",
       "2              0.0              0.0                  0.0          0.0   \n",
       "3              0.0              0.0                  0.0          0.0   \n",
       "4              0.0              0.0                  0.0          0.0   \n",
       "\n",
       "   token_abidjan  token_abilities  token_ability  token_abolition  \\\n",
       "0            0.0              0.0            0.0              0.0   \n",
       "1            0.0              0.0            0.0              0.0   \n",
       "2            0.0              0.0            4.0              0.0   \n",
       "3            0.0              0.0            0.0              0.0   \n",
       "4            0.0              0.0            0.0              0.0   \n",
       "\n",
       "   token_abortion  token_abovementioned  token_abreast  token_abridged  \\\n",
       "0             0.0                   0.0            0.0             0.0   \n",
       "1             0.0                   0.0            0.0             0.0   \n",
       "2             0.0                   0.0            0.0             0.0   \n",
       "3             0.0                   0.0            0.0             0.0   \n",
       "4             0.0                   0.0            0.0             0.0   \n",
       "\n",
       "   token_abroad  token_abrupt  token_absence  token_absent  token_absenteeism  \\\n",
       "0           0.0           0.0            0.0           0.0                0.0   \n",
       "1           0.0           0.0            0.0           0.0                0.0   \n",
       "2           0.0           0.0            1.0           0.0                0.0   \n",
       "3           0.0           0.0            0.0           0.0                0.0   \n",
       "4           0.0           0.0            0.0           0.0                0.0   \n",
       "\n",
       "   ...  token_youre  token_youth  token_youths  token_yugoslav  \\\n",
       "0  ...          0.0          0.0           0.0             0.0   \n",
       "1  ...          0.0          0.0           0.0             0.0   \n",
       "2  ...          0.0          0.0           0.0             0.0   \n",
       "3  ...          0.0          0.0           0.0             0.0   \n",
       "4  ...          0.0          0.0           0.0             0.0   \n",
       "\n",
       "   token_yugoslavia  token_yunnan  token_yusuf  token_zaidi  token_zaman  \\\n",
       "0               0.0           0.0          0.0          0.0          0.0   \n",
       "1               0.0           0.0          0.0          0.0          0.0   \n",
       "2               0.0           0.0          0.0          0.0          0.0   \n",
       "3               0.0           0.0          0.0          0.0          0.0   \n",
       "4               0.0           0.0          0.0          0.0          0.0   \n",
       "\n",
       "   token_zambia  token_zambian  token_zambias  token_zanzibar  token_zation  \\\n",
       "0           0.0            0.0            0.0             0.0           0.0   \n",
       "1           0.0            0.0            0.0             0.0           0.0   \n",
       "2           0.0            0.0            0.0             0.0           0.0   \n",
       "3           0.0            0.0            0.0             0.0           0.0   \n",
       "4           0.0            0.0            0.0             0.0           0.0   \n",
       "\n",
       "   token_zealand  token_zeroduty  token_zhang  token_zimbabwe  \\\n",
       "0            0.0             0.0          0.0             0.0   \n",
       "1            0.0             0.0          0.0             0.0   \n",
       "2            0.0             0.0          0.0             0.0   \n",
       "3            0.0             0.0          0.0             0.0   \n",
       "4            0.0             0.0          0.0             0.0   \n",
       "\n",
       "   token_zimbabwes  token_zingales  token_zoellick  token_zones  token_zoning  \\\n",
       "0              0.0             0.0             0.0          0.0           0.0   \n",
       "1              0.0             0.0             0.0          0.0           0.0   \n",
       "2              0.0             0.0             0.0          0.0           0.0   \n",
       "3              0.0             0.0             0.0          0.0           0.0   \n",
       "4              0.0             0.0             0.0          0.0           0.0   \n",
       "\n",
       "   token_zscore  token_zusammenarbeit  \n",
       "0           0.0                   0.0  \n",
       "1           0.0                   0.0  \n",
       "2           0.0                   0.0  \n",
       "3           0.0                   0.0  \n",
       "4           0.0                   0.0  \n",
       "\n",
       "[5 rows x 10006 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['row_id',\n",
    "            'information_and_communication_technologies',\n",
    "            'governance',\n",
    "            'urban_development',\n",
    "            'law_and_development',\n",
    "            'public_sector_development',\n",
    "            'agriculture',\n",
    "            'communities_and_human_settlements',\n",
    "            'health_and_nutrition_and_population',\n",
    "            'culture_and_development',\n",
    "            'social_protections_and_labor',\n",
    "            'international_economics_and_trade',\n",
    "            'conflict_and_development',\n",
    "            'science_and_technology_development',\n",
    "            'rural_development',\n",
    "            'poverty_reduction',\n",
    "            'social_development',\n",
    "            'education',\n",
    "            'transport',\n",
    "            'gender',\n",
    "            'infrastructure_economics_and_finance',\n",
    "            'energy_and_environment',\n",
    "            'finance_and_development',\n",
    "            'macroeconomics_and_growth', \n",
    "            'water'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../../wb-publications-data/submission_format.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission__svc_df = pd.read_csv('../../wb-publications-data/submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in submission__svc_df.columns:\n",
    "    if topic in topics:       \n",
    "        with open('./svc_classifiers/' + topic + '.pkl', 'rb') as pickle_file:\n",
    "            svc = pickle.load(pickle_file)\n",
    "        submission__svc_df[topic] = svc.predict(df_val[:])\n",
    "        \n",
    "submission__svc_df = submission__svc_df.astype(int)\n",
    "\n",
    "submission__svc_df.to_csv('./submission_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpsvc = pd.read_csv('./submission_svc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>information_and_communication_technologies</th>\n",
       "      <th>governance</th>\n",
       "      <th>urban_development</th>\n",
       "      <th>law_and_development</th>\n",
       "      <th>public_sector_development</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>communities_and_human_settlements</th>\n",
       "      <th>health_and_nutrition_and_population</th>\n",
       "      <th>culture_and_development</th>\n",
       "      <th>social_protections_and_labor</th>\n",
       "      <th>international_economics_and_trade</th>\n",
       "      <th>conflict_and_development</th>\n",
       "      <th>science_and_technology_development</th>\n",
       "      <th>rural_development</th>\n",
       "      <th>poverty_reduction</th>\n",
       "      <th>social_development</th>\n",
       "      <th>education</th>\n",
       "      <th>transport</th>\n",
       "      <th>gender</th>\n",
       "      <th>infrastructure_economics_and_finance</th>\n",
       "      <th>energy_and_environment</th>\n",
       "      <th>finance_and_development</th>\n",
       "      <th>macroeconomics_and_growth</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  information_and_communication_technologies  governance  \\\n",
       "0       0                                           0           0   \n",
       "1       1                                           0           0   \n",
       "2       2                                           1           0   \n",
       "3       3                                           0           1   \n",
       "4       4                                           0           0   \n",
       "\n",
       "   urban_development  law_and_development  public_sector_development  \\\n",
       "0                  0                    0                          0   \n",
       "1                  0                    0                          0   \n",
       "2                  0                    1                          0   \n",
       "3                  0                    0                          1   \n",
       "4                  0                    0                          0   \n",
       "\n",
       "   agriculture  communities_and_human_settlements  \\\n",
       "0            0                                  0   \n",
       "1            0                                  0   \n",
       "2            0                                  0   \n",
       "3            0                                  0   \n",
       "4            0                                  0   \n",
       "\n",
       "   health_and_nutrition_and_population  culture_and_development  \\\n",
       "0                                    0                        0   \n",
       "1                                    0                        0   \n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        0   \n",
       "\n",
       "   social_protections_and_labor  international_economics_and_trade  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  1   \n",
       "4                             1                                  0   \n",
       "\n",
       "   conflict_and_development  science_and_technology_development  \\\n",
       "0                         0                                   0   \n",
       "1                         0                                   0   \n",
       "2                         0                                   0   \n",
       "3                         0                                   0   \n",
       "4                         0                                   0   \n",
       "\n",
       "   rural_development  poverty_reduction  social_development  education  \\\n",
       "0                  0                  0                   0          1   \n",
       "1                  0                  1                   0          1   \n",
       "2                  0                  0                   0          0   \n",
       "3                  0                  1                   0          0   \n",
       "4                  0                  0                   0          0   \n",
       "\n",
       "   transport  gender  infrastructure_economics_and_finance  \\\n",
       "0          0       1                                     0   \n",
       "1          0       0                                     0   \n",
       "2          0       0                                     0   \n",
       "3          0       0                                     0   \n",
       "4          0       0                                     0   \n",
       "\n",
       "   energy_and_environment  finance_and_development  macroeconomics_and_growth  \\\n",
       "0                       0                        0                          0   \n",
       "1                       0                        0                          0   \n",
       "2                       0                        1                          1   \n",
       "3                       0                        0                          0   \n",
       "4                       0                        1                          1   \n",
       "\n",
       "   water  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpsvc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinominal Niave Bayes Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission__lr_df = pd.read_csv('../../wb-publications-data/submission_format.csv')\n",
    "for topic in submission__lr_df.columns:\n",
    "    if topic in topics:       \n",
    "        with open('./lr_classifier/' + topic + '.pkl', 'rb') as pickle_file:\n",
    "            lr = pickle.load(pickle_file)\n",
    "        submission__lr_df[topic] = lr.predict(df_val[:])\n",
    "        \n",
    "submission__lr_df = submission__lr_df.astype(int)\n",
    "submission__lr_df.to_csv('./submission_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>information_and_communication_technologies</th>\n",
       "      <th>governance</th>\n",
       "      <th>urban_development</th>\n",
       "      <th>law_and_development</th>\n",
       "      <th>public_sector_development</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>communities_and_human_settlements</th>\n",
       "      <th>health_and_nutrition_and_population</th>\n",
       "      <th>culture_and_development</th>\n",
       "      <th>social_protections_and_labor</th>\n",
       "      <th>international_economics_and_trade</th>\n",
       "      <th>conflict_and_development</th>\n",
       "      <th>science_and_technology_development</th>\n",
       "      <th>rural_development</th>\n",
       "      <th>poverty_reduction</th>\n",
       "      <th>social_development</th>\n",
       "      <th>education</th>\n",
       "      <th>transport</th>\n",
       "      <th>gender</th>\n",
       "      <th>infrastructure_economics_and_finance</th>\n",
       "      <th>energy_and_environment</th>\n",
       "      <th>finance_and_development</th>\n",
       "      <th>macroeconomics_and_growth</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  information_and_communication_technologies  governance  \\\n",
       "0       0                                           0           0   \n",
       "1       1                                           0           0   \n",
       "2       2                                           1           0   \n",
       "3       3                                           0           1   \n",
       "4       4                                           0           0   \n",
       "\n",
       "   urban_development  law_and_development  public_sector_development  \\\n",
       "0                  0                    0                          0   \n",
       "1                  0                    0                          0   \n",
       "2                  0                    0                          0   \n",
       "3                  0                    0                          1   \n",
       "4                  0                    0                          0   \n",
       "\n",
       "   agriculture  communities_and_human_settlements  \\\n",
       "0            0                                  0   \n",
       "1            0                                  0   \n",
       "2            0                                  0   \n",
       "3            0                                  0   \n",
       "4            0                                  0   \n",
       "\n",
       "   health_and_nutrition_and_population  culture_and_development  \\\n",
       "0                                    0                        0   \n",
       "1                                    0                        0   \n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        0   \n",
       "\n",
       "   social_protections_and_labor  international_economics_and_trade  \\\n",
       "0                             1                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  1   \n",
       "4                             0                                  0   \n",
       "\n",
       "   conflict_and_development  science_and_technology_development  \\\n",
       "0                         0                                   0   \n",
       "1                         0                                   0   \n",
       "2                         0                                   0   \n",
       "3                         0                                   0   \n",
       "4                         0                                   0   \n",
       "\n",
       "   rural_development  poverty_reduction  social_development  education  \\\n",
       "0                  0                  0                   0          0   \n",
       "1                  0                  0                   0          1   \n",
       "2                  0                  0                   0          0   \n",
       "3                  0                  0                   0          0   \n",
       "4                  0                  0                   0          0   \n",
       "\n",
       "   transport  gender  infrastructure_economics_and_finance  \\\n",
       "0          0       0                                     0   \n",
       "1          0       0                                     0   \n",
       "2          0       0                                     0   \n",
       "3          0       0                                     0   \n",
       "4          0       0                                     0   \n",
       "\n",
       "   energy_and_environment  finance_and_development  macroeconomics_and_growth  \\\n",
       "0                       0                        0                          0   \n",
       "1                       0                        0                          0   \n",
       "2                       0                        1                          1   \n",
       "3                       0                        0                          0   \n",
       "4                       0                        1                          1   \n",
       "\n",
       "   water  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpsvc = pd.read_csv('./submission_lr.csv')\n",
    "tmpsvc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
